Course curriculum, Colab toolkit and data links

Hi, and welcome to this modern NLP course! Here is a quick summary of the different parts of the course and the links to the Google Colab file for each application. Enjoy!

1. Introduction

2. BERT's intuition

3. Application 1: apply BERT's tokenizer for data preprocessing (sentimental analyser):
        Google Colab file: https://colab.research.google.com/drive/12noBxRkrZnIkHqvmdfFW2TGdOXFtNePM
        Data link: http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip

4. Application 2: use BERT as an embedding layer for your personal NLP model (sentiment analyser):
        Google Colab file: https://colab.research.google.com/drive/19ltEkQHc1vaQDMzkdCY5T-pnKQKDOhPv
        Data link: http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip

5. Application3: fine-tune BERT to create a question answering system (SQuaD benchmark):
        Google Colab file: https://colab.research.google.com/drive/1P9blY216XBeh570nWe7g4znjqw6QHskx
        Data link: training set https://drive.google.com/file/d/1zwSjQX2gNb2EYldVoR5sCibnSDz9DQtH/view?usp=sharing
                          dev set https://drive.google.com/file/d/1YjCrVa3906b4KCWTQu3KySY7gE1CPqpC/view?usp=sharing
                          vocab.txt https://drive.google.com/file/d/1kp8ApuoHSjROy0Rca0BNQ6YrnbpRtYCk/view?usp=sharing
                          evaluation script https://drive.google.com/file/d/1DKhqdc8tdMnZ4EzLtW2zuG0Pf6z6H3vF/view?usp=sharing